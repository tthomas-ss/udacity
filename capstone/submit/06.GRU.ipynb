{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "1bfa1b01eb23052d0ebd4a432397e5f7d867a4a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, GlobalAveragePooling1D, CuDNNLSTM, CuDNNGRU, Conv1D, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split, KFold\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "\n",
    "from capstone_utils import *\n",
    "\n",
    "# Inline plotting\n",
    "%matplotlib inline\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('max_colwidth', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "1d0f6fca4b1c84e383dd4a82da2f18bdd41accfc"
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 150\n",
    "MAX_VOCAB_SIZE = 30000\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "ef82d6ee6721cf9608e8b1cca35917bdd8f9f927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading questions...\n",
      "Done loading train - Loading test\n",
      "Done loading test\n"
     ]
    }
   ],
   "source": [
    "train, test, corpus = load_data('../data', clean=False, lower_stop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9221d5a8721b1655abe18f1996020c4445929a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Word: . - could not convert string to float: '.'\n",
      "Word: at - could not convert string to float: 'name@domain.com'\n",
      "Word: . - could not convert string to float: '.'\n",
      "Word: to - could not convert string to float: 'name@domain.com'\n",
      "Word: . - could not convert string to float: '.'\n",
      "Word: . - could not convert string to float: '.'\n",
      "Word: email - could not convert string to float: 'name@domain.com'\n",
      "Word: or - could not convert string to float: 'name@domain.com'\n",
      "Word: contact - could not convert string to float: 'name@domain.com'\n",
      "Word: Email - could not convert string to float: 'name@domain.com'\n",
      "Word: on - could not convert string to float: 'name@domain.com'\n",
      "Word: At - could not convert string to float: 'Killerseats.com'\n",
      "Word: by - could not convert string to float: 'name@domain.com'\n",
      "Word: in - could not convert string to float: 'mylot.com'\n",
      "Word: emailing - could not convert string to float: 'name@domain.com'\n",
      "Word: Contact - could not convert string to float: 'name@domain.com'\n",
      "Word: at - could not convert string to float: 'name@domain.com'\n",
      "Word: â€¢ - could not convert string to float: 'name@domain.com'\n",
      "Word: at - could not convert string to float: 'Amazon.com'\n",
      "Word: is - could not convert string to float: 'name@domain.com'\n",
      "Found 2195884 word vectors.\n"
     ]
    }
   ],
   "source": [
    "word2vec = load_embeddings(path='../data/glove.840B.300d/glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "ae6dfa003b86ad242352a7268f6e92d48834e8d1"
   },
   "outputs": [],
   "source": [
    "# convert the sentences (strings) into integers\n",
    "targets = train['target'].values\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(train[\"question_text\"])\n",
    "test_sequences = tokenizer.texts_to_sequences(test['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "81c7685e889db9c83432222e5953e6c1949585cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 227538 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# get word -> integer mapping\n",
    "word2idx = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = load_embedding_matrix(word2idx, word2vec, MAX_VOCAB_SIZE, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "730b93ffd8927e4485ad45c9066930ef25b1e8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1306122, 150)\n"
     ]
    }
   ],
   "source": [
    "# pad sequences so that we get a N x T matrix\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "21336f9908a9aa203f92f2a4c5580f8537126e63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of testdata tensor: (56370, 150)\n"
     ]
    }
   ],
   "source": [
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of testdata tensor:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "582520344658023de69ce859f28d83081e0cf577"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "83bb6288a76aa89a5cafc73aea1483af7bd746f0"
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "  MAX_VOCAB_SIZE,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=MAX_SEQUENCE_LENGTH,\n",
    "  trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "ba670f548f8bb2055fd2f0994ef4db5e73d64ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 300)          9000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 150, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 9,150,913\n",
      "Trainable params: 150,913\n",
      "Non-trainable params: 9,000,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_cp_filepath = 'gru_embeddings.ep-{epoch:02d}-loss-{val_loss:.2f}.hdf5'\n",
    "\n",
    "optimizer = Adam(lr=0.001, decay=0.0001);\n",
    "\n",
    "input_layer = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = embedding_layer (input_layer)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "# x = Bidirectional(CuDNNLSTM(32, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=input_layer, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "f352df6abd4f9efae805e8cd9f6bd7cdd53c1636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for 4 epochs\n",
      "Train on 914285 samples, validate on 391837 samples\n",
      "Epoch 1/4\n",
      "914285/914285 [==============================] - 217s 237us/step - loss: 0.1244 - acc: 0.9515 - val_loss: 0.1065 - val_acc: 0.9582\n",
      "Epoch 2/4\n",
      "914285/914285 [==============================] - 216s 237us/step - loss: 0.1067 - acc: 0.9580 - val_loss: 0.1047 - val_acc: 0.9589\n",
      "Epoch 3/4\n",
      "914285/914285 [==============================] - 216s 236us/step - loss: 0.1014 - acc: 0.9598 - val_loss: 0.1016 - val_acc: 0.9599\n",
      "Epoch 4/4\n",
      "914285/914285 [==============================] - 216s 237us/step - loss: 0.0968 - acc: 0.9617 - val_loss: 0.1012 - val_acc: 0.9599\n"
     ]
    }
   ],
   "source": [
    "print('Training model for {} epochs'.format(EPOCHS))\n",
    "\n",
    "model_cp = ModelCheckpoint(model_cp_filepath, monitor='val_loss', verbose=0, \n",
    "                     save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "r = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                   validation_data=(X_test, y_test), callbacks=[model_cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "958cfb0288494fe6b09c6267b92109344bae8d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.586451892072975\n",
      "F1 score at threshold 0.11 is 0.5951677584164633\n",
      "F1 score at threshold 0.12 is 0.6026550864870378\n",
      "F1 score at threshold 0.13 is 0.6093661783496271\n",
      "F1 score at threshold 0.14 is 0.6156289707750953\n",
      "F1 score at threshold 0.15 is 0.6215529585662155\n",
      "F1 score at threshold 0.16 is 0.626492449730068\n",
      "F1 score at threshold 0.17 is 0.6311789490420542\n",
      "F1 score at threshold 0.18 is 0.6353100687606933\n",
      "F1 score at threshold 0.19 is 0.6392933093407492\n",
      "F1 score at threshold 0.2 is 0.6427836932364747\n",
      "F1 score at threshold 0.21 is 0.645983193277311\n",
      "F1 score at threshold 0.22 is 0.6489182426336664\n",
      "F1 score at threshold 0.23 is 0.6514488509113462\n",
      "F1 score at threshold 0.24 is 0.6535952272965146\n",
      "F1 score at threshold 0.25 is 0.6556897311591008\n",
      "F1 score at threshold 0.26 is 0.6576001711107942\n",
      "F1 score at threshold 0.27 is 0.6597002017872586\n",
      "F1 score at threshold 0.28 is 0.661300602771657\n",
      "F1 score at threshold 0.29 is 0.6620171871262168\n",
      "F1 score at threshold 0.3 is 0.6635064041789823\n",
      "F1 score at threshold 0.31 is 0.6639747586673177\n",
      "F1 score at threshold 0.32 is 0.6641744311820408\n",
      "F1 score at threshold 0.33 is 0.6644555214723926\n",
      "F1 score at threshold 0.34 is 0.6650786273142768\n",
      "F1 score at threshold 0.35 is 0.664907032670538\n",
      "F1 score at threshold 0.36 is 0.6646547132966447\n",
      "F1 score at threshold 0.37 is 0.6645287228109314\n",
      "F1 score at threshold 0.38 is 0.6639860069563119\n",
      "F1 score at threshold 0.39 is 0.663484971567831\n",
      "F1 score at threshold 0.4 is 0.662785214949056\n",
      "F1 score at threshold 0.41 is 0.6624174823582972\n",
      "F1 score at threshold 0.42 is 0.660829955284383\n",
      "F1 score at threshold 0.43 is 0.6598199034142432\n",
      "F1 score at threshold 0.44 is 0.6584062506653041\n",
      "F1 score at threshold 0.45 is 0.6571103135544046\n",
      "F1 score at threshold 0.46 is 0.6551851289503938\n",
      "F1 score at threshold 0.47 is 0.653292744355139\n",
      "F1 score at threshold 0.48 is 0.6511967437950714\n",
      "F1 score at threshold 0.49 is 0.6482767863125684\n",
      "F1 score at threshold 0.5 is 0.6457144146379984\n",
      "F1 score at threshold 0.51 is 0.6427382391170501\n",
      "F1 score at threshold 0.52 is 0.6391690847957257\n",
      "F1 score at threshold 0.53 is 0.6360565611386774\n",
      "F1 score at threshold 0.54 is 0.6325281348589725\n",
      "F1 score at threshold 0.55 is 0.6279629320818544\n",
      "F1 score at threshold 0.56 is 0.6221590224386012\n",
      "F1 score at threshold 0.57 is 0.6166605683619955\n",
      "F1 score at threshold 0.58 is 0.6099150701165318\n",
      "F1 score at threshold 0.59 is 0.6041703084030466\n",
      "F1 score at threshold 0.6 is 0.5963527834686496\n",
      "F1 score at threshold 0.61 is 0.5888829147143917\n",
      "F1 score at threshold 0.62 is 0.581474950731252\n",
      "F1 score at threshold 0.63 is 0.5728183419661873\n",
      "F1 score at threshold 0.64 is 0.563223294757613\n",
      "F1 score at threshold 0.65 is 0.5528375998916429\n",
      "F1 score at threshold 0.66 is 0.5417515274949084\n",
      "F1 score at threshold 0.67 is 0.5291224147568474\n",
      "F1 score at threshold 0.68 is 0.5138240983046991\n",
      "F1 score at threshold 0.69 is 0.4994361391435098\n",
      "F1 score at threshold 0.7 is 0.48368973732976445\n",
      "F1 score at threshold 0.71 is 0.46653289808631065\n",
      "F1 score at threshold 0.72 is 0.4488625968164908\n",
      "F1 score at threshold 0.73 is 0.42939678200906994\n",
      "F1 score at threshold 0.74 is 0.4084783296425182\n",
      "F1 score at threshold 0.75 is 0.3864017546123081\n",
      "F1 score at threshold 0.76 is 0.36275122528864184\n",
      "F1 score at threshold 0.77 is 0.3403499363142723\n",
      "F1 score at threshold 0.78 is 0.3164189304630104\n",
      "F1 score at threshold 0.79 is 0.2901258234289498\n",
      "F1 score at threshold 0.8 is 0.26549678519413167\n",
      "F1 score at threshold 0.81 is 0.23813319805783026\n",
      "F1 score at threshold 0.82 is 0.20994719935014583\n",
      "F1 score at threshold 0.83 is 0.18199601248918484\n",
      "F1 score at threshold 0.84 is 0.1537047673750718\n",
      "F1 score at threshold 0.85 is 0.12908998949538963\n",
      "F1 score at threshold 0.86 is 0.10285398055182228\n",
      "F1 score at threshold 0.87 is 0.0804358275917321\n",
      "F1 score at threshold 0.88 is 0.0599894613108508\n",
      "F1 score at threshold 0.89 is 0.04314190986860955\n",
      "Best F1 0.6650786273142768 at 0.34\n"
     ]
    }
   ],
   "source": [
    "val_predictions = model.predict(X_test)\n",
    "best_threshold = threshold_search(y_test, val_predictions, min_threshold=0.1, max_threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "e284eaa2436f6469dd8a29a84250c27c968ac642"
   },
   "outputs": [],
   "source": [
    "submission_predictions = model.predict(test_data)\n",
    "submission_best_predictions = (submission_predictions > best_threshold.get('threshold')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "9ebe26e48ffed5c03d8d15b53f63b5fbcfce7d66"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"qid\":test[\"qid\"].values})\n",
    "submission['prediction'] = submission_best_predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# For itesations on capstone_utils\n",
    "import importlib\n",
    "import capstone_utils\n",
    "importlib.reload(capstone_utils)\n",
    "from capstone_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean for other models\n",
    "import gc\n",
    "del model\n",
    "gc.collect()\n",
    "from keras import backend as K\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
