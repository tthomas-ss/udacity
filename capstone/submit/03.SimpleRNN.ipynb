{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "1bfa1b01eb23052d0ebd4a432397e5f7d867a4a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, GlobalAveragePooling1D, CuDNNLSTM, CuDNNGRU, Conv1D, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, Flatten, Bidirectional, GlobalMaxPool1D,SimpleRNN\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split, KFold\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "\n",
    "from capstone_utils import *\n",
    "\n",
    "# Inline plotting\n",
    "%matplotlib inline\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('max_colwidth', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "1d0f6fca4b1c84e383dd4a82da2f18bdd41accfc"
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 150\n",
    "MAX_VOCAB_SIZE = 30000\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "ef82d6ee6721cf9608e8b1cca35917bdd8f9f927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading questions...\n",
      "Done loading train - Loading test\n",
      "Done loading test\n"
     ]
    }
   ],
   "source": [
    "train, test, corpus = load_data('../data', clean=False, lower_stop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9221d5a8721b1655abe18f1996020c4445929a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Word: . - could not convert string to float: '.'\n",
      "Word: at - could not convert string to float: 'name@domain.com'\n",
      "Word: . - could not convert string to float: '.'\n",
      "Word: to - could not convert string to float: 'name@domain.com'\n",
      "Word: . - could not convert string to float: '.'\n",
      "Word: . - could not convert string to float: '.'\n",
      "Word: email - could not convert string to float: 'name@domain.com'\n",
      "Word: or - could not convert string to float: 'name@domain.com'\n",
      "Word: contact - could not convert string to float: 'name@domain.com'\n",
      "Word: Email - could not convert string to float: 'name@domain.com'\n",
      "Word: on - could not convert string to float: 'name@domain.com'\n",
      "Word: At - could not convert string to float: 'Killerseats.com'\n",
      "Word: by - could not convert string to float: 'name@domain.com'\n",
      "Word: in - could not convert string to float: 'mylot.com'\n",
      "Word: emailing - could not convert string to float: 'name@domain.com'\n",
      "Word: Contact - could not convert string to float: 'name@domain.com'\n",
      "Word: at - could not convert string to float: 'name@domain.com'\n",
      "Word: â€¢ - could not convert string to float: 'name@domain.com'\n",
      "Word: at - could not convert string to float: 'Amazon.com'\n",
      "Word: is - could not convert string to float: 'name@domain.com'\n",
      "Found 2195884 word vectors.\n"
     ]
    }
   ],
   "source": [
    "word2vec = load_embeddings(path='../data/glove.840B.300d/glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "ae6dfa003b86ad242352a7268f6e92d48834e8d1"
   },
   "outputs": [],
   "source": [
    "# convert the sentences (strings) into integers\n",
    "targets = train['target'].values\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(train[\"question_text\"])\n",
    "test_sequences = tokenizer.texts_to_sequences(test['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "81c7685e889db9c83432222e5953e6c1949585cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 227538 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# get word -> integer mapping\n",
    "word2idx = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = load_embedding_matrix(word2idx, word2vec, MAX_VOCAB_SIZE, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "730b93ffd8927e4485ad45c9066930ef25b1e8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1306122, 150)\n"
     ]
    }
   ],
   "source": [
    "# pad sequences so that we get a N x T matrix\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "21336f9908a9aa203f92f2a4c5580f8537126e63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of testdata tensor: (56370, 150)\n"
     ]
    }
   ],
   "source": [
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of testdata tensor:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "582520344658023de69ce859f28d83081e0cf577"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "83bb6288a76aa89a5cafc73aea1483af7bd746f0"
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "  MAX_VOCAB_SIZE,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=MAX_SEQUENCE_LENGTH,\n",
    "  trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "ba670f548f8bb2055fd2f0994ef4db5e73d64ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 300)          9000000   \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 64)                23360     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 9,029,633\n",
      "Trainable params: 29,633\n",
      "Non-trainable params: 9,000,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_cp_filepath = 'simplernn.ep-{epoch:02d}-loss-{val_loss:.2f}.hdf5'\n",
    "\n",
    "optimizer = Adam(lr=0.001, decay=0.0001);\n",
    "\n",
    "input_layer = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = embedding_layer (input_layer)\n",
    "x = SimpleRNN(64, return_sequences=False)(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=input_layer, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "f352df6abd4f9efae805e8cd9f6bd7cdd53c1636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for 4 epochs\n",
      "Train on 914285 samples, validate on 391837 samples\n",
      "Epoch 1/4\n",
      "914285/914285 [==============================] - 225s 246us/step - loss: 0.1450 - acc: 0.9439 - val_loss: 0.1220 - val_acc: 0.9512\n",
      "Epoch 2/4\n",
      "914285/914285 [==============================] - 223s 244us/step - loss: 0.1375 - acc: 0.9456 - val_loss: 0.1224 - val_acc: 0.9511\n",
      "Epoch 3/4\n",
      "914285/914285 [==============================] - 223s 244us/step - loss: 0.1245 - acc: 0.9506 - val_loss: 0.1195 - val_acc: 0.9531\n",
      "Epoch 4/4\n",
      "914285/914285 [==============================] - 223s 244us/step - loss: 0.1201 - acc: 0.9525 - val_loss: 0.1163 - val_acc: 0.9538\n"
     ]
    }
   ],
   "source": [
    "print('Training model for {} epochs'.format(EPOCHS))\n",
    "\n",
    "model_cp = ModelCheckpoint(model_cp_filepath, monitor='val_loss', verbose=0, \n",
    "                     save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "r = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                   validation_data=(X_test, y_test), callbacks=[model_cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "958cfb0288494fe6b09c6267b92109344bae8d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.5399354201691886\n",
      "F1 score at threshold 0.11 is 0.5493385917344508\n",
      "F1 score at threshold 0.12 is 0.557013118062563\n",
      "F1 score at threshold 0.13 is 0.5633012017130498\n",
      "F1 score at threshold 0.14 is 0.5693460510363564\n",
      "F1 score at threshold 0.15 is 0.5752449593471722\n",
      "F1 score at threshold 0.16 is 0.5804103543969792\n",
      "F1 score at threshold 0.17 is 0.5845522434117139\n",
      "F1 score at threshold 0.18 is 0.587947422906798\n",
      "F1 score at threshold 0.19 is 0.5910220466420288\n",
      "F1 score at threshold 0.2 is 0.5943849100518838\n",
      "F1 score at threshold 0.21 is 0.5974153604245491\n",
      "F1 score at threshold 0.22 is 0.5999867215509228\n",
      "F1 score at threshold 0.23 is 0.6026650514839491\n",
      "F1 score at threshold 0.24 is 0.6043413071628161\n",
      "F1 score at threshold 0.25 is 0.6066772435676347\n",
      "F1 score at threshold 0.26 is 0.6081765178228538\n",
      "F1 score at threshold 0.27 is 0.6098935061724033\n",
      "F1 score at threshold 0.28 is 0.6116048278945017\n",
      "F1 score at threshold 0.29 is 0.6129008904655034\n",
      "F1 score at threshold 0.3 is 0.613921156132809\n",
      "F1 score at threshold 0.31 is 0.6141132535911704\n",
      "F1 score at threshold 0.32 is 0.6145967666573218\n",
      "F1 score at threshold 0.33 is 0.615018328861343\n",
      "F1 score at threshold 0.34 is 0.6156930891592033\n",
      "F1 score at threshold 0.35 is 0.6153371631260361\n",
      "F1 score at threshold 0.36 is 0.6152406938218671\n",
      "F1 score at threshold 0.37 is 0.6145823083735117\n",
      "F1 score at threshold 0.38 is 0.6142874170606698\n",
      "F1 score at threshold 0.39 is 0.6138022295292326\n",
      "F1 score at threshold 0.4 is 0.6129378199550798\n",
      "F1 score at threshold 0.41 is 0.6124724332271502\n",
      "F1 score at threshold 0.42 is 0.6110493598452101\n",
      "F1 score at threshold 0.43 is 0.6106062492219595\n",
      "F1 score at threshold 0.44 is 0.609498294158277\n",
      "F1 score at threshold 0.45 is 0.6086791337751699\n",
      "F1 score at threshold 0.46 is 0.6067626266927859\n",
      "F1 score at threshold 0.47 is 0.60563652364292\n",
      "F1 score at threshold 0.48 is 0.6043813317170317\n",
      "F1 score at threshold 0.49 is 0.603187077057411\n",
      "F1 score at threshold 0.5 is 0.6009342087868506\n",
      "F1 score at threshold 0.51 is 0.5985404707871668\n",
      "F1 score at threshold 0.52 is 0.5957752486138235\n",
      "F1 score at threshold 0.53 is 0.5919807574485465\n",
      "F1 score at threshold 0.54 is 0.5876004592422504\n",
      "F1 score at threshold 0.55 is 0.5828877005347595\n",
      "F1 score at threshold 0.56 is 0.5776991984912777\n",
      "F1 score at threshold 0.57 is 0.5727879121141846\n",
      "F1 score at threshold 0.58 is 0.5667272506967164\n",
      "F1 score at threshold 0.59 is 0.5600923742138364\n",
      "F1 score at threshold 0.6 is 0.5527437732179811\n",
      "F1 score at threshold 0.61 is 0.543248730964467\n",
      "F1 score at threshold 0.62 is 0.5330305532617671\n",
      "F1 score at threshold 0.63 is 0.5225021674592124\n",
      "F1 score at threshold 0.64 is 0.5095852213314743\n",
      "F1 score at threshold 0.65 is 0.4917375789184738\n",
      "F1 score at threshold 0.66 is 0.4724112717250689\n",
      "F1 score at threshold 0.67 is 0.4499118216774119\n",
      "F1 score at threshold 0.68 is 0.4243201335877862\n",
      "F1 score at threshold 0.69 is 0.39336580553671613\n",
      "F1 score at threshold 0.7 is 0.3606463333014629\n",
      "F1 score at threshold 0.71 is 0.322152525586002\n",
      "F1 score at threshold 0.72 is 0.28443594385054133\n",
      "F1 score at threshold 0.73 is 0.24303169824685675\n",
      "F1 score at threshold 0.74 is 0.20256035113386978\n",
      "F1 score at threshold 0.75 is 0.16227623892971546\n",
      "F1 score at threshold 0.76 is 0.12784046993352913\n",
      "F1 score at threshold 0.77 is 0.09832314065890708\n",
      "F1 score at threshold 0.78 is 0.06967213114754099\n",
      "F1 score at threshold 0.79 is 0.049951187764399614\n",
      "F1 score at threshold 0.8 is 0.03426599285097991\n",
      "F1 score at threshold 0.81 is 0.02128100028981907\n",
      "F1 score at threshold 0.82 is 0.01281624500665779\n",
      "F1 score at threshold 0.83 is 0.007844446298923474\n",
      "F1 score at threshold 0.84 is 0.004264392324093817\n",
      "F1 score at threshold 0.85 is 0.0027617373838814963\n",
      "F1 score at threshold 0.86 is 0.0012563340173374095\n",
      "F1 score at threshold 0.87 is 0.0006702412868632708\n",
      "F1 score at threshold 0.88 is 0.0003351768057650411\n",
      "F1 score at threshold 0.89 is 0.00016760244699572617\n",
      "Best F1 0.6156930891592033 at 0.34\n"
     ]
    }
   ],
   "source": [
    "val_predictions = model.predict(X_test)\n",
    "best_threshold = threshold_search(y_test, val_predictions, min_threshold=0.1, max_threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "e284eaa2436f6469dd8a29a84250c27c968ac642"
   },
   "outputs": [],
   "source": [
    "submission_predictions = model.predict(test_data)\n",
    "submission_best_predictions = (submission_predictions > best_threshold.get('threshold')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "9ebe26e48ffed5c03d8d15b53f63b5fbcfce7d66"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"qid\":test[\"qid\"].values})\n",
    "submission['prediction'] = submission_best_predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import capstone_utils\n",
    "importlib.reload(capstone_utils)\n",
    "from capstone_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For clearing memory\n",
    "import gc\n",
    "from keras import backend as K\n",
    "del model\n",
    "gc.collect()\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the above does not work\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
